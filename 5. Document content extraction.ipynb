{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Document content extraction using Azure Content Understanding\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/media/overview/content-understanding-framework-2025.png#lightbox\">\n",
    "\n",
    "Azure Content Understanding in Foundry Tools is an Foundry Tool that's available as part of the Microsoft Foundry Resource in the Azure portal. It uses generative AI to process/ingest content of many types (documents, images, videos, and audio) into a user-defined output format. Content Understanding offers a streamlined process to reason over large amounts of unstructured data, accelerating time-to-value by generating an output that can be integrated into automation and analytical workflows.\n",
    "\n",
    "Content Understanding is now a Generally Available (GA) service with the release of the 2025-11-01 API version. It's now available in a broader range of regions.\n",
    "\n",
    "### Core Documentation\n",
    "1. **[What is Azure Content Understanding in Foundry Tools?](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/overview)** - Main overview page\n",
    "2. **[FAQ - Frequently Asked Questions](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/faq)** - Common questions and answers\n",
    "3. **[Choosing the Right Tool: Document Intelligence vs Content Understanding](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/choosing-right-ai-tool)** - Comparison guide\n",
    "4. **[Models and Deployments](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/concepts/models-deployments)** - Supported models configuration\n",
    "5. **[Pricing Explainer](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/pricing-explainer)** - Pricing details and optimization\n",
    "\n",
    "### Modality-Specific Documentation\n",
    "6. **[Document Processing Overview](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/document/overview)** - Field extraction and grounding\n",
    "7. **[Video Solutions (Preview)](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/video/overview)** - Video analysis capabilities\n",
    "8. **[Image Solutions (Preview)](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/image/overview)** - Image extraction and analysis\n",
    "9. **[Face Solutions (Preview)](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/face/overview)** - Face detection and recognition\n",
    "\n",
    "### Additional Resources\n",
    "10. **[Transparency Note](https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/content-understanding/transparency-note)** - Responsible AI information\n",
    "11. **[Code Samples on GitHub](https://github.com/Azure-Samples/azure-ai-content-understanding-python)** - Python implementation examples\n",
    "12. **[Azure Content Understanding Pricing](https://azure.microsoft.com/pricing/details/content-understanding/)** - Official pricing page\n",
    "\n",
    "## Document Content\n",
    "\n",
    "The `prebuilt-documentSearch` analyzer transforms unstructured documents into structured, machine-readable data optimized for retrieval-augmented generation (RAG) and automated workflows. It extracts content and layout elements while preserving document structure and semantic relationships.\n",
    "\n",
    "Key capabilities include:\n",
    "1. **Content Analysis:** Extracts text (printed and handwritten), selection marks, barcodes (12+ types), mathematical formulas (LaTeX), hyperlinks, and annotations.\n",
    "2. **Figure Analysis:** Generates descriptions for images/charts/diagrams, converts charts to Chart.js syntax, and diagrams to Mermaid.js syntax.\n",
    "3. **Structure Analysis:** Identifies paragraphs with contextual roles (title, section heading, page header/footer), detects tables with complex layouts (merged cells, multi-page), and maps hierarchical sections.\n",
    "4. **GitHub Flavored Markdown:** Outputs richly formatted markdown that preserves document structure for LLM comprehension and AI-powered analysis.\n",
    "5. **Broad Format Support:** Processes PDFs, images, Office documents (Word, Excel, PowerPoint), text files (HTML, Markdown), structured files (XML, JSON, CSV), and email formats (EML, MSG).\n",
    "\n",
    "For detailed information about document elements and markdown representation, see [Document elements](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/document/elements) and [Document markdown](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/document/markdown).\n",
    "\n",
    "> **Note:** Figure analysis (descriptions and chart/diagram analysis) is only supported for PDF and image file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from helper.content_understanding_client import AzureContentUnderstandingClient\n",
    "from helper.document_processor import DocumentProcessor\n",
    "from helper.sample_helper import save_json_to_file \n",
    "from IPython.display import FileLink\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 02-Dec-2025 13:27:12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Azure Content Understanding client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "API_VERSION = \"2025-11-01\"  # Subject to change. Check the documentation\n",
    "GPT_4_1_DEPLOYMENT = \"gpt-4.1\"  # Name of the model deployed in Microsoft Foundry\n",
    "GPT_4_1_MINI_DEPLOYMENT = \"gpt-4.1-mini\"  # Name of the model deployed in Microsoft Foundry\n",
    "TEXT_EMBEDDING_3_LARGE_DEPLOYMENT = \"text-embedding-3-large\"  # Name of the model deployed in Microsoft Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Azure Content Understanding Client...\n",
      "‚úÖ Done\n"
     ]
    }
   ],
   "source": [
    "def token_provider():\n",
    "    \"\"\"Provides fresh Azure Cognitive Services tokens.\"\"\"\n",
    "    try:\n",
    "        credential = DefaultAzureCredential()\n",
    "        token = credential.get_token(\n",
    "            \"https://cognitiveservices.azure.com/.default\")\n",
    "        return token.token\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Token acquisition failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "try:\n",
    "    if not AZURE_AI_ENDPOINT or not API_VERSION:\n",
    "        raise ValueError(\"AZURE_AI_ENDPOINT and API_VERSION must be set\")\n",
    "\n",
    "    print(\"Initializing Azure Content Understanding Client...\")\n",
    "    client = AzureContentUnderstandingClient(\n",
    "        endpoint=AZURE_AI_ENDPOINT,\n",
    "        api_version=API_VERSION,\n",
    "        token_provider=token_provider,\n",
    "        x_ms_useragent=\"azure-ai-content-understanding-python-sample-ga\")\n",
    "    print(\"‚úÖ Done\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Configuration error: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Client creation failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuring default model deployments...\n",
      "   GPT-4.1 deployment: gpt-4.1\n",
      "   GPT-4.1-mini deployment: gpt-4.1-mini\n",
      "   text-embedding-3-large deployment: text-embedding-3-large\n",
      "\n",
      "‚úÖ Default model deployments configured successfully\n",
      "   Model mappings:\n",
      "     gpt-4.1 ‚Üí gpt-4.1\n",
      "     gpt-4.1-mini ‚Üí gpt-4.1-mini\n",
      "     text-embedding-3-large ‚Üí text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "missing_deployments = []\n",
    "\n",
    "if not GPT_4_1_DEPLOYMENT:\n",
    "    missing_deployments.append(\"GPT_4_1_DEPLOYMENT\")\n",
    "if not GPT_4_1_MINI_DEPLOYMENT:\n",
    "    missing_deployments.append(\"GPT_4_1_MINI_DEPLOYMENT\")\n",
    "if not TEXT_EMBEDDING_3_LARGE_DEPLOYMENT:\n",
    "    missing_deployments.append(\"TEXT_EMBEDDING_3_LARGE_DEPLOYMENT\")\n",
    "\n",
    "if missing_deployments:\n",
    "    print(f\"‚ùå Warning: Missing required model deployment configuration(s):\")\n",
    "    for deployment in missing_deployments:\n",
    "        print(f\"   - {deployment}\")\n",
    "    print(\n",
    "        \"\\n   Prebuilt analyzers require GPT-4.1, GPT-4.1-mini, and text-embedding-3-large deployments.\"\n",
    "    )\n",
    "    print(\"   Please:\")\n",
    "    print(\"   1. Deploy all three models in Azure AI Foundry\")\n",
    "    print(\"   2. Add the following to notebooks/.env:\")\n",
    "    print(\"      GPT_4_1_DEPLOYMENT=<your-gpt-4.1-deployment-name>\")\n",
    "    print(\"      GPT_4_1_MINI_DEPLOYMENT=<your-gpt-4.1-mini-deployment-name>\")\n",
    "    print(\n",
    "        \"      TEXT_EMBEDDING_3_LARGE_DEPLOYMENT=<your-text-embedding-3-large-deployment-name>\"\n",
    "    )\n",
    "    print(\"   3. Restart the kernel and run this cell again\")\n",
    "\n",
    "else:\n",
    "    print(f\"üìã Configuring default model deployments...\")\n",
    "    print(f\"   GPT-4.1 deployment: {GPT_4_1_DEPLOYMENT}\")\n",
    "    print(f\"   GPT-4.1-mini deployment: {GPT_4_1_MINI_DEPLOYMENT}\")\n",
    "    print(\n",
    "        f\"   text-embedding-3-large deployment: {TEXT_EMBEDDING_3_LARGE_DEPLOYMENT}\"\n",
    "    )\n",
    "    try:\n",
    "        result = client.update_defaults({\n",
    "            \"gpt-4.1\":\n",
    "            GPT_4_1_DEPLOYMENT,\n",
    "            \"gpt-4.1-mini\":\n",
    "            GPT_4_1_MINI_DEPLOYMENT,\n",
    "            \"text-embedding-3-large\":\n",
    "            TEXT_EMBEDDING_3_LARGE_DEPLOYMENT\n",
    "        })\n",
    "        print(f\"\\n‚úÖ Default model deployments configured successfully\")\n",
    "        print(f\"   Model mappings:\")\n",
    "        for model, deployment in result.get(\"modelDeployments\", {}).items():\n",
    "            print(f\"     {model} ‚Üí {deployment}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to configure defaults: {e}\")\n",
    "        print(f\"   This may happen if:\")\n",
    "        print(\n",
    "            f\"   - One or more deployment names don't exist in your Azure AI Foundry project\"\n",
    "        )\n",
    "        print(f\"   - You don't have permission to update defaults\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved default settings\n",
      "\n",
      "‚úÖ Model Deployments:\n",
      "   gpt-4.1: gpt-4.1\n",
      "   gpt-4.1-mini: gpt-4.1-mini\n",
      "   text-embedding-3-large: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    defaults = client.get_defaults()\n",
    "    print(f\"‚úÖ Retrieved default settings\")\n",
    "\n",
    "    model_deployments = defaults.get(\"modelDeployments\", {})\n",
    "\n",
    "    if model_deployments:\n",
    "        print(f\"\\n‚úÖ Model Deployments:\")\n",
    "        for model_name, deployment_name in model_deployments.items():\n",
    "            print(f\"   {model_name}: {deployment_name}\")\n",
    "    else:\n",
    "        print(\"‚ùå No model deployments configured\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå  Error retrieving defaults: {e}\")\n",
    "    print(\"This is expected if no defaults have been configured yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 148K Dec  2 13:20 documents/invoice.pdf\n"
     ]
    }
   ],
   "source": [
    "document_file = os.path.join(DOCS_DIR, \"invoice.pdf\")\n",
    "\n",
    "!ls $document_file -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='documents/invoice.pdf' target='_blank'>documents/invoice.pdf</a><br>"
      ],
      "text/plain": [
       "/mnt/batch/tasks/shared/LS_root/mounts/clusters/standardd48/code/Users/seretkow/ACU/documents/invoice.pdf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_link = FileLink(path=document_file)\n",
    "doc_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing documents/invoice.pdf with prebuilt-documentSearch...\n",
      "\u001b[1;31;34m\n",
      "üìÑ Markdown Content:\n",
      "==================================================\n",
      "CONTOSO LTD.\n",
      "\n",
      "\n",
      "# INVOICE\n",
      "\n",
      "Contoso Headquarters\n",
      "123 456th St\n",
      "New York, NY, 10001\n",
      "\n",
      "INVOICE: INV-100\n",
      "\n",
      "INVOICE DATE: 11/15/2019\n",
      "\n",
      "DUE DATE: 12/15/2019\n",
      "\n",
      "CUSTOMER NAME: MICROSOFT CORPORATION\n",
      "\n",
      "SERVICE PERIOD: 10/14/2019 - 11/14/2019\n",
      "\n",
      "CUSTOMER ID: CID-12345\n",
      "\n",
      "Microsoft Corp\n",
      "123 Other St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "BILL TO:\n",
      "Microsoft Finance\n",
      "123 Bill St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "SHIP TO:\n",
      "Microsoft Delivery\n",
      "123 Ship St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "SERVICE ADDRESS:\n",
      "Microsoft Services\n",
      "123 Service St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>SALESPERSON</th>\n",
      "<th>P.O. NUMBER</th>\n",
      "<th>REQUISITIONER</th>\n",
      "<th>SHIPPED VIA</th>\n",
      "<th>F.O.B. POINT</th>\n",
      "<th>TERMS</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td></td>\n",
      "<td>PO-3333</td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>DATE</th>\n",
      "<th>ITEM CODE</th>\n",
      "<th>DESCRIPTION</th>\n",
      "<th>QTY</th>\n",
      "<th>UM</th>\n",
      "<th>PRICE</th>\n",
      "<th>TAX</th>\n",
      "<th>AMOUNT</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/4/2021</td>\n",
      "<td>A123</td>\n",
      "<td>Consulting Services</td>\n",
      "<td>2</td>\n",
      "<td>hours</td>\n",
      "<td>$30.00</td>\n",
      "<td>$6.00</td>\n",
      "<td>$60.00</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/5/2021</td>\n",
      "<td>B456</td>\n",
      "<td>Document Fee</td>\n",
      "<td>3</td>\n",
      "<td></td>\n",
      "<td>$10.00</td>\n",
      "<td>$3.00</td>\n",
      "<td>$30.00</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/6/2021</td>\n",
      "<td>C789</td>\n",
      "<td>Printing Fee</td>\n",
      "<td>10</td>\n",
      "<td>pages</td>\n",
      "<td>$1.00</td>\n",
      "<td>$1.00</td>\n",
      "<td>$10.00</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>SUBTOTAL</th>\n",
      "<th>$100.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>SALES TAX</th>\n",
      "<th>$10.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>TOTAL</th>\n",
      "<th>$110.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>PREVIOUS UNPAID BALANCE</th>\n",
      "<th>$500.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>AMOUNT DUE</th>\n",
      "<th>$610.00</th>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "THANK YOU FOR YOUR BUSINESS!\n",
      "\n",
      "REMIT TO:\n",
      "Contoso Billing\n",
      "123 Remit St\n",
      "New York, NY, 10001\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìö Document Information:\n",
      "Start page: 1\n",
      "End page: 1\n",
      "Total pages: 1\n",
      "\n",
      "üìÑ Pages (1):\n",
      "  Page 1: 8.5 x 11 inch\n",
      "\n",
      "üìä Tables (3):\n",
      "  Table 1: 2 rows x 6 columns\n",
      "  Table 2: 4 rows x 8 columns\n",
      "  Table 3: 5 rows x 2 columns\n",
      "üíæ Analysis result saved to: results/content_analyzers_analyze_binary_20251202_132720.json\n",
      "\n",
      "üìã Full analysis result saved. Review the complete JSON at: results/content_analyzers_analyze_binary_20251202_132720.json\n"
     ]
    }
   ],
   "source": [
    "# Analyze document from local file\n",
    "analyzer_id = 'prebuilt-documentSearch'\n",
    "\n",
    "print(f\"üîç Analyzing {document_file} with {analyzer_id}...\")\n",
    "response = client.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    file_location=document_file,\n",
    ")\n",
    "\n",
    "result = client.poll_result(response)\n",
    "\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(\"üìÑ Markdown Content:\")\n",
    "print(\"=\" * 50)\n",
    "# Extract markdown from the first content element\n",
    "contents = result.get(\"result\", {}).get(\"contents\", [])\n",
    "if contents:\n",
    "    content = contents[0]\n",
    "    markdown = content.get(\"markdown\", \"\")\n",
    "    print(markdown)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if this is document content to access document-specific properties\n",
    "if content.get(\"kind\") == \"document\":\n",
    "    document_content = content\n",
    "    print(f\"\\nüìö Document Information:\")\n",
    "    print(f\"Start page: {document_content.get('startPageNumber')}\")\n",
    "    print(f\"End page: {document_content.get('endPageNumber')}\")\n",
    "    print(\n",
    "        f\"Total pages: {document_content.get('endPageNumber') - document_content.get('startPageNumber') + 1}\"\n",
    "    )\n",
    "\n",
    "    # Check for pages\n",
    "    pages = document_content.get(\"pages\")\n",
    "    if pages is not None:\n",
    "        print(f\"\\nüìÑ Pages ({len(pages)}):\")\n",
    "        for i, page in enumerate(pages):\n",
    "            unit = document_content.get(\"unit\", \"units\")\n",
    "            print(\n",
    "                f\"  Page {page.get('pageNumber')}: {page.get('width')} x {page.get('height')} {unit}\"\n",
    "            )\n",
    "\n",
    "    # Check if there are tables in the document\n",
    "    tables = document_content.get(\"tables\")\n",
    "    if tables is not None:\n",
    "        print(f\"\\nüìä Tables ({len(tables)}):\")\n",
    "        table_counter = 1\n",
    "        for table in tables:\n",
    "            row_count = table.get(\"rowCount\")\n",
    "            col_count = table.get(\"columnCount\")\n",
    "            print(\n",
    "                f\"  Table {table_counter}: {row_count} rows x {col_count} columns\"\n",
    "            )\n",
    "            table_counter += 1\n",
    "else:\n",
    "    print(\"\\nüìö Document Information: Not available for this content type\")\n",
    "\n",
    "# Save the result\n",
    "saved_json_path = save_json_to_file(\n",
    "    result, filename_prefix=\"content_analyzers_analyze_binary\")\n",
    "print(\n",
    "    f\"\\nüìã Full analysis result saved. Review the complete JSON at: {saved_json_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing Documents from URLs\n",
    "\n",
    "You can also analyze documents directly from publicly accessible URLs without downloading them first. This is useful for processing documents hosted on web servers, cloud storage, or GitHub repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing document from URL: https://github.com/Azure-Samples/azure-ai-content-understanding-python/raw/refs/heads/main/data/invoice.pdf\n",
      "üìä Using analyzer: prebuilt-documentSearch\n",
      "\n",
      "\u001b[1;31;34m\n",
      "üìÑ Markdown Content:\n",
      "==================================================\n",
      "CONTOSO LTD.\n",
      "\n",
      "\n",
      "# INVOICE\n",
      "\n",
      "Contoso Headquarters\n",
      "123 456th St\n",
      "New York, NY, 10001\n",
      "\n",
      "INVOICE: INV-100\n",
      "\n",
      "INVOICE DATE: 11/15/2019\n",
      "\n",
      "DUE DATE: 12/15/2019\n",
      "\n",
      "CUSTOMER NAME: MICROSOFT CORPORATION\n",
      "\n",
      "SERVICE PERIOD: 10/14/2019 - 11/14/2019\n",
      "\n",
      "CUSTOMER ID: CID-12345\n",
      "\n",
      "Microsoft Corp\n",
      "123 Other St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "BILL TO:\n",
      "Microsoft Finance\n",
      "123 Bill St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "SHIP TO:\n",
      "Microsoft Delivery\n",
      "123 Ship St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "SERVICE ADDRESS:\n",
      "Microsoft Services\n",
      "123 Service St,\n",
      "Redmond WA, 98052\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>SALESPERSON</th>\n",
      "<th>P.O. NUMBER</th>\n",
      "<th>REQUISITIONER</th>\n",
      "<th>SHIPPED VIA</th>\n",
      "<th>F.O.B. POINT</th>\n",
      "<th>TERMS</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td></td>\n",
      "<td>PO-3333</td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "<td></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>DATE</th>\n",
      "<th>ITEM CODE</th>\n",
      "<th>DESCRIPTION</th>\n",
      "<th>QTY</th>\n",
      "<th>UM</th>\n",
      "<th>PRICE</th>\n",
      "<th>TAX</th>\n",
      "<th>AMOUNT</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/4/2021</td>\n",
      "<td>A123</td>\n",
      "<td>Consulting Services</td>\n",
      "<td>2</td>\n",
      "<td>hours</td>\n",
      "<td>$30.00</td>\n",
      "<td>$6.00</td>\n",
      "<td>$60.00</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/5/2021</td>\n",
      "<td>B456</td>\n",
      "<td>Document Fee</td>\n",
      "<td>3</td>\n",
      "<td></td>\n",
      "<td>$10.00</td>\n",
      "<td>$3.00</td>\n",
      "<td>$30.00</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3/6/2021</td>\n",
      "<td>C789</td>\n",
      "<td>Printing Fee</td>\n",
      "<td>10</td>\n",
      "<td>pages</td>\n",
      "<td>$1.00</td>\n",
      "<td>$1.00</td>\n",
      "<td>$10.00</td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>SUBTOTAL</th>\n",
      "<th>$100.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>SALES TAX</th>\n",
      "<th>$10.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>TOTAL</th>\n",
      "<th>$110.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>PREVIOUS UNPAID BALANCE</th>\n",
      "<th>$500.00</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>AMOUNT DUE</th>\n",
      "<th>$610.00</th>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "THANK YOU FOR YOUR BUSINESS!\n",
      "\n",
      "REMIT TO:\n",
      "Contoso Billing\n",
      "123 Remit St\n",
      "New York, NY, 10001\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìö Document Information:\n",
      "Start page: 1\n",
      "End page: 1\n",
      "Total pages: 1\n",
      "\n",
      "üìÑ Pages (1):\n",
      "  Page 1: 8.5 x 11 inch\n",
      "\n",
      "üìä Tables (3):\n",
      "  Table 1: 2 rows x 6 columns\n",
      "  Table 2: 4 rows x 8 columns\n",
      "  Table 3: 5 rows x 2 columns\n",
      "üíæ Analysis result saved to: results/content_analyzers_url_document_20251202_132726.json\n",
      "\n",
      "üìã Full analysis result saved. Review the complete JSON at: results/content_analyzers_url_document_20251202_132726.json\n"
     ]
    }
   ],
   "source": [
    "document_url = 'https://github.com/Azure-Samples/azure-ai-content-understanding-python/raw/refs/heads/main/data/invoice.pdf'\n",
    "analyzer_id = 'prebuilt-documentSearch'\n",
    "\n",
    "print(f\"üîç Analyzing document from URL: {document_url}\")\n",
    "print(f\"üìä Using analyzer: {analyzer_id}\\n\")\n",
    "\n",
    "response = client.begin_analyze_url(\n",
    "    analyzer_id=analyzer_id,\n",
    "    url=document_url,\n",
    ")\n",
    "\n",
    "result = client.poll_result(response)\n",
    "\n",
    "print(\"\\033[1;31;34m\")\n",
    "print(\"üìÑ Markdown Content:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract markdown from the first content element\n",
    "contents = result.get(\"result\", {}).get(\"contents\", [])\n",
    "if contents:\n",
    "    content = contents[0]\n",
    "    markdown = content.get(\"markdown\", \"\")\n",
    "    print(markdown)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if this is document content to access document-specific properties\n",
    "if content.get(\"kind\") == \"document\":\n",
    "    document_content = content\n",
    "    print(f\"\\nüìö Document Information:\")\n",
    "    print(f\"Start page: {document_content.get('startPageNumber')}\")\n",
    "    print(f\"End page: {document_content.get('endPageNumber')}\")\n",
    "    print(\n",
    "        f\"Total pages: {document_content.get('endPageNumber') - document_content.get('startPageNumber') + 1}\"\n",
    "    )\n",
    "\n",
    "    # Check for pages\n",
    "    pages = document_content.get(\"pages\")\n",
    "    if pages is not None:\n",
    "        print(f\"\\nüìÑ Pages ({len(pages)}):\")\n",
    "        for i, page in enumerate(pages):\n",
    "            unit = document_content.get(\"unit\", \"units\")\n",
    "            print(\n",
    "                f\"  Page {page.get('pageNumber')}: {page.get('width')} x {page.get('height')} {unit}\"\n",
    "            )\n",
    "\n",
    "    # Check if there are tables in the document\n",
    "    tables = document_content.get(\"tables\")\n",
    "    if tables is not None:\n",
    "        print(f\"\\nüìä Tables ({len(tables)}):\")\n",
    "        table_counter = 1\n",
    "        for table in tables:\n",
    "            row_count = table.get(\"rowCount\")\n",
    "            col_count = table.get(\"columnCount\")\n",
    "            print(\n",
    "                f\"  Table {table_counter}: {row_count} rows x {col_count} columns\"\n",
    "            )\n",
    "            table_counter += 1\n",
    "else:\n",
    "    print(\"\\nüìö Document Information: Not available for this content type\")\n",
    "\n",
    "# Save the result\n",
    "saved_json_path = save_json_to_file(\n",
    "    result, filename_prefix=\"content_analyzers_url_document\")\n",
    "print(\n",
    "    f\"\\nüìã Full analysis result saved. Review the complete JSON at: {saved_json_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 136K Dec  2 13:27 results/content_analyzers_url_document_20251202_132726.json\n"
     ]
    }
   ],
   "source": [
    "!ls $saved_json_path -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
